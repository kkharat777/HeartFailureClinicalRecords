{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,:-1]\n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.500e+01, 0.000e+00, 5.820e+02, ..., 1.000e+00, 0.000e+00,\n",
       "        4.000e+00],\n",
       "       [5.500e+01, 0.000e+00, 7.861e+03, ..., 1.000e+00, 0.000e+00,\n",
       "        6.000e+00],\n",
       "       [6.500e+01, 0.000e+00, 1.460e+02, ..., 1.000e+00, 1.000e+00,\n",
       "        7.000e+00],\n",
       "       ...,\n",
       "       [4.500e+01, 0.000e+00, 2.060e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        2.780e+02],\n",
       "       [4.500e+01, 0.000e+00, 2.413e+03, ..., 1.000e+00, 1.000e+00,\n",
       "        2.800e+02],\n",
       "       [5.000e+01, 0.000e+00, 1.960e+02, ..., 1.000e+00, 1.000e+00,\n",
       "        2.850e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.19294523e+00 -8.71104775e-01  1.65728387e-04 ...  7.35688190e-01\n",
      "  -6.87681906e-01 -1.62950241e+00]\n",
      " [-4.91279276e-01 -8.71104775e-01  7.51463953e+00 ...  7.35688190e-01\n",
      "  -6.87681906e-01 -1.60369074e+00]\n",
      " [ 3.50832977e-01 -8.71104775e-01 -4.49938761e-01 ...  7.35688190e-01\n",
      "   1.45416070e+00 -1.59078490e+00]\n",
      " ...\n",
      " [-1.33339153e+00 -8.71104775e-01  1.52597865e+00 ... -1.35927151e+00\n",
      "  -6.87681906e-01  1.90669738e+00]\n",
      " [-1.33339153e+00 -8.71104775e-01  1.89039811e+00 ...  7.35688190e-01\n",
      "   1.45416070e+00  1.93250906e+00]\n",
      " [-9.12335403e-01 -8.71104775e-01 -3.98321274e-01 ...  7.35688190e-01\n",
      "   1.45416070e+00  1.99703825e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X , Y, test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0)]\n",
      "[[ 0.59452136 -0.10417641  0.43997831  0.0969067  -0.97885927 -0.05562098\n",
      "  -0.03988825  0.32580176 -0.25613616 -0.37733294  0.04240945 -1.57682894]]\n",
      "[-1.42419445]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print(list(zip(Y_test, Y_pred)))\n",
    "print(classifier.coef_)\n",
    "print(classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55  4]\n",
      " [11 20]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.93      0.88        59\n",
      "         1.0       0.83      0.65      0.73        31\n",
      "\n",
      "    accuracy                           0.83        90\n",
      "   macro avg       0.83      0.79      0.80        90\n",
      "weighted avg       0.83      0.83      0.83        90\n",
      "\n",
      "Accuracy of the model: 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98954827 0.01045173]\n",
      " [0.73587974 0.26412026]\n",
      " [0.98487369 0.01512631]\n",
      " [0.98827353 0.01172647]\n",
      " [0.78159787 0.21840213]\n",
      " [0.13357866 0.86642134]\n",
      " [0.6964215  0.3035785 ]\n",
      " [0.89391539 0.10608461]\n",
      " [0.42887602 0.57112398]\n",
      " [0.94541693 0.05458307]\n",
      " [0.61575957 0.38424043]\n",
      " [0.72697061 0.27302939]\n",
      " [0.97044449 0.02955551]\n",
      " [0.92888684 0.07111316]\n",
      " [0.93363215 0.06636785]\n",
      " [0.10400828 0.89599172]\n",
      " [0.9605307  0.0394693 ]\n",
      " [0.96040855 0.03959145]\n",
      " [0.0456696  0.9543304 ]\n",
      " [0.99776411 0.00223589]\n",
      " [0.62880831 0.37119169]\n",
      " [0.88262301 0.11737699]\n",
      " [0.4639566  0.5360434 ]\n",
      " [0.9628672  0.0371328 ]\n",
      " [0.87318579 0.12681421]\n",
      " [0.95624391 0.04375609]\n",
      " [0.87333719 0.12666281]\n",
      " [0.98917787 0.01082213]\n",
      " [0.52864985 0.47135015]\n",
      " [0.74071068 0.25928932]\n",
      " [0.99346978 0.00653022]\n",
      " [0.98034942 0.01965058]\n",
      " [0.36124475 0.63875525]\n",
      " [0.65978275 0.34021725]\n",
      " [0.70907395 0.29092605]\n",
      " [0.52335746 0.47664254]\n",
      " [0.99040495 0.00959505]\n",
      " [0.80098271 0.19901729]\n",
      " [0.22096384 0.77903616]\n",
      " [0.8613344  0.1386656 ]\n",
      " [0.4390168  0.5609832 ]\n",
      " [0.98373919 0.01626081]\n",
      " [0.35806845 0.64193155]\n",
      " [0.57091052 0.42908948]\n",
      " [0.73048912 0.26951088]\n",
      " [0.99155967 0.00844033]\n",
      " [0.86863723 0.13136277]\n",
      " [0.10668719 0.89331281]\n",
      " [0.91137365 0.08862635]\n",
      " [0.8725174  0.1274826 ]\n",
      " [0.97970293 0.02029707]\n",
      " [0.97250761 0.02749239]\n",
      " [0.02162364 0.97837636]\n",
      " [0.86541477 0.13458523]\n",
      " [0.99106345 0.00893655]\n",
      " [0.30723647 0.69276353]\n",
      " [0.95751676 0.04248324]\n",
      " [0.368865   0.631135  ]\n",
      " [0.64929885 0.35070115]\n",
      " [0.22808881 0.77191119]\n",
      " [0.91915188 0.08084812]\n",
      " [0.95493658 0.04506342]\n",
      " [0.12916074 0.87083926]\n",
      " [0.26529081 0.73470919]\n",
      " [0.86428084 0.13571916]\n",
      " [0.98684769 0.01315231]\n",
      " [0.34450669 0.65549331]\n",
      " [0.99217303 0.00782697]\n",
      " [0.94826034 0.05173966]\n",
      " [0.07173834 0.92826166]\n",
      " [0.96357213 0.03642787]\n",
      " [0.27365601 0.72634399]\n",
      " [0.76454224 0.23545776]\n",
      " [0.94981264 0.05018736]\n",
      " [0.78320914 0.21679086]\n",
      " [0.84890295 0.15109705]\n",
      " [0.98243023 0.01756977]\n",
      " [0.98771168 0.01228832]\n",
      " [0.99810139 0.00189861]\n",
      " [0.1796398  0.8203602 ]\n",
      " [0.94637291 0.05362709]\n",
      " [0.94375113 0.05624887]\n",
      " [0.14745718 0.85254282]\n",
      " [0.10848131 0.89151869]\n",
      " [0.79445704 0.20554296]\n",
      " [0.99500787 0.00499213]\n",
      " [0.07884034 0.92115966]\n",
      " [0.73047663 0.26952337]\n",
      " [0.97766038 0.02233962]\n",
      " [0.17971966 0.82028034]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\\n                       max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort=False,\\n                       random_state=10, splitter='best/random')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting using the Decision_Tree_Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",random_state=10)#,min_samples_leaf=5,max_depth=10\n",
    "\n",
    "#fit the model on the Data and predict the values\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "\n",
    "\"\"\"\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=10, splitter='best/random')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  6]\n",
      " [14 17]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84        59\n",
      "         1.0       0.74      0.55      0.63        31\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.77      0.72      0.74        90\n",
      "weighted avg       0.77      0.78      0.77        90\n",
      "\n",
      "Accuracy of the model: 77.77777777777779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Bagging_Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    " \n",
    "model=ExtraTreesClassifier(100,random_state=10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    " \n",
    "Y_pred=model.predict(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  2]\n",
      " [11 20]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.97      0.90        59\n",
      "         1.0       0.91      0.65      0.75        31\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.87      0.81      0.83        90\n",
      "weighted avg       0.86      0.86      0.85        90\n",
      "\n",
      "Accuracy of the model: 85.55555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#predicting using the Random_Forest_Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "model_RandomForest=RandomForestClassifier(n_estimators=101,random_state=10)\n",
    " \n",
    "#fit the model on the data and predict the values\n",
    "model_RandomForest.fit(X_train,Y_train)\n",
    " \n",
    "Y_pred=model_RandomForest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  3]\n",
      " [11 20]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89        59\n",
      "         1.0       0.87      0.65      0.74        31\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.85      0.80      0.81        90\n",
      "weighted avg       0.85      0.84      0.84        90\n",
      "\n",
      "Accuracy of the model: 84.44444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions using AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the AdaBoost_Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    " \n",
    "model_AdaBoost=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                  n_estimators=10,\n",
    "                                  random_state=10)\n",
    "#fit the model on the data and predict the values\n",
    "model_AdaBoost.fit(X_train,Y_train)\n",
    "Y_pred=model_AdaBoost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  6]\n",
      " [15 16]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.90      0.83        59\n",
      "         1.0       0.73      0.52      0.60        31\n",
      "\n",
      "    accuracy                           0.77        90\n",
      "   macro avg       0.75      0.71      0.72        90\n",
      "weighted avg       0.76      0.77      0.76        90\n",
      "\n",
      "Accuracy of the model: 76.66666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions using Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Gradient_Boosting_Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    " \n",
    "model_GradientBoosting=GradientBoostingClassifier(n_estimators=270,\n",
    "                                                  random_state=10)\n",
    " \n",
    "#fit the model on the data and predict the values\n",
    "model_GradientBoosting.fit(X_train,Y_train)\n",
    " \n",
    "Y_pred=model_GradientBoosting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  5]\n",
      " [11 20]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.92      0.87        59\n",
      "         1.0       0.80      0.65      0.71        31\n",
      "\n",
      "    accuracy                           0.82        90\n",
      "   macro avg       0.82      0.78      0.79        90\n",
      "weighted avg       0.82      0.82      0.82        90\n",
      "\n",
      "Accuracy of the model: 82.22222222222221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " \n",
    "# create the sub models\n",
    "estimators = []\n",
    "#model1 = LogisticRegression()\n",
    "#estimators.append(('log', model1))\n",
    "\n",
    "model2 = DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "estimators.append(('cart', model2))\n",
    "\n",
    "model3 = SVC(kernel=\"rbf\", C=50,gamma=0.1)\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "model4 = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "estimators.append(('knn', model4))\n",
    " \n",
    "# create the ensemble model\n",
    "\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)\n",
    "#print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  3]\n",
      " [15 16]]\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.95      0.86        59\n",
      "         1.0       0.84      0.52      0.64        31\n",
      "\n",
      "    accuracy                           0.80        90\n",
      "   macro avg       0.82      0.73      0.75        90\n",
      "weighted avg       0.81      0.80      0.79        90\n",
      "\n",
      "Accuracy of the model: 80.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print (\"Classification report\")\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print (\"Accuracy of the model:\", acc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14448929 0.13686856 0.11507235 0.08969845 0.08700071 0.07455907\n",
      " 0.07388457 0.07205403 0.05651353 0.05527437 0.05356264 0.04102245]\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = None)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_    #provie us the Eigen values\n",
    "print(explained_variance)  #[0.72908626 0.22643525 0.03935829 0.00512019]  nut we dont know thic varble is this belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14448929 0.13686856 0.11507235 0.08969845 0.08700071 0.07455907\n",
      " 0.07388457 0.07205403]\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.75)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVC to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel=\"rbf\",gamma=0.1,C=1)\n",
    "classifier.fit(X_train, Y_train)\n",
    "# Predicting the Test set results\n",
    "Y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  5]\n",
      " [11 20]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.92      0.87        59\n",
      "         1.0       0.80      0.65      0.71        31\n",
      "\n",
      "    accuracy                           0.82        90\n",
      "   macro avg       0.82      0.78      0.79        90\n",
      "weighted avg       0.82      0.82      0.82        90\n",
      "\n",
      "Accuracy of the model:  0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
